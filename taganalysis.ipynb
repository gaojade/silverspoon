{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "\n",
    "# create driver for selenium\n",
    "driver = webdriver.Chrome('/Users/lionheart/anaconda3/pkgs/chromedriver-binary-2.38-0/bin/chromedriver-binary')\n",
    "driver.get('https://www.tumblr.com/search/ed recovery')\n",
    "\n",
    "# click link to find results, if applicable\n",
    "try:\n",
    "    link = driver.find_element_by_link_text('View search results')\n",
    "    link.click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "# Selenium script for infinite scroll; scrolls down a maximum of 25 times\n",
    "lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "match=False\n",
    "counter = 25\n",
    "while(match==False or counter > 0):\n",
    "    lastCount = lenOfPage\n",
    "    time.sleep(5)\n",
    "    lenOfPage = driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "    if lastCount==lenOfPage:\n",
    "        match=True\n",
    "    counter -= 1\n",
    "\n",
    "# retrieves source code\n",
    "source_data = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- IMPORTS ---\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "# instantiate new BeautifulSoup object\n",
    "soup = BeautifulSoup(source_data, \"html.parser\")\n",
    "    \n",
    "# finds all post tags\n",
    "posts = soup.findAll(\"a\", {\"class\": \"post_tag\"})\n",
    "\n",
    "# creates empty list for post tags\n",
    "nlp_sample = []\n",
    "\n",
    "for x in posts:\n",
    "    # removes all indents, apostrophes, hashtags\n",
    "    posttext = x.text.replace('\\n','').replace('â€™','').replace('#','')\n",
    "    # removes all punctuation\n",
    "    posttext = posttext.translate(str.maketrans('', '', string.punctuation))\n",
    "    # tokenizes tags into individual words\n",
    "    tokens = nltk.word_tokenize(posttext.lower())\n",
    "    nlp_sample.extend(tokens)\n",
    "\n",
    "print(nlp_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreqDist({'recovery': 597, 'ed': 415, 'self': 155, 'eating': 137, 'mental': 124, 'health': 86, 'disorder': 85, 'ana': 76, 'positive': 75, 'memes': 72, 'love': 64, 'anorexia': 63, 'body': 61, 'pro': 60, 'depression': 59, 'positivity': 58, 'care': 48, 'personal': 37, 'binge': 36, 'blog': 36, 'quotes': 35, 'food': 33, 'vegan': 28, 'illness': 27, 'thinspo': 26, 'ednos': 26, 'anxiety': 26, 'tw': 26, 'help': 24, 'anorexya': 22, 'warrior': 21, 'bulimia': 20, 'problems': 20, 'disorders': 19, 'weight': 18, 'anamia': 18, 'osfed': 18, 'mia': 17, 'bulimiia': 17, 'mine': 16, 'therapy': 16, 'life': 15, 'recover': 15, 'reminder': 15, 'disroders': 14, 'disoder': 14, 'imaginethisinstead': 14, 'healthy': 13, 'text': 13, 'meme': 13, 'worth': 13, 'bpd': 13, 'happiness': 13, 'healing': 12, 'recovering': 12, 'confidence': 12, 'relapse': 12, 'support': 11, 'pastel': 11, 'happy': 11, 'im': 11, 'anorexa': 10, 'harm': 10, 'affirmations': 10, 'skinny': 10, 'fitspo': 9, 'thinspiration': 9, 'feminism': 9, 'hope': 9, 'image': 9, 'advice': 9, 'loving': 9, 'actually': 8, 'reminders': 8, 'humour': 8, 'mention': 8, 'wholesome': 8, 'lgbtq': 8, 'motivation': 8, 'things': 8, 'tags': 8, 'anorexyc': 8, 'vegans': 8, 'eat': 8, 'meanspo': 8, 'sweetspo': 8, 'tips': 8, 'like': 7, 'fitness': 7, 'posititivity': 7, 'bonespo': 7, 'ptsd': 7, 'good': 7, 'growth': 7, 'inspirational': 7, 'poetry': 7, 'ocd': 7, 'diet': 7, 'bulimix': 7, 'aesthetic': 7, ...})\n"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# identifies English stopwords and removes them from list of tags\n",
    "sr = stopwords.words('english')\n",
    "clean_tokens = nlp_sample[:]\n",
    "for token in nlp_sample:\n",
    "    if token in stopwords.words('english'):\n",
    "        clean_tokens.remove(token)\n",
    "\n",
    "# creates frequency distribution of tags\n",
    "freq = nltk.FreqDist(t for t in clean_tokens)\n",
    "\n",
    "freq.pprint(100, stream=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
